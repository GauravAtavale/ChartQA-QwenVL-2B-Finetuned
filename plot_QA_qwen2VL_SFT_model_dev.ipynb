{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n!pip install pip3-autoremove\n!pip-autoremove torch torchvision torchaudio -y\n!pip install torch torchvision torchaudio xformers --index-url https://download.pytorch.org/whl/cu121\n!pip install unsloth","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-13T01:57:23.121060Z","iopub.execute_input":"2025-09-13T01:57:23.121714Z","iopub.status.idle":"2025-09-13T02:00:37.309006Z","shell.execute_reply.started":"2025-09-13T01:57:23.121688Z","shell.execute_reply":"2025-09-13T02:00:37.308085Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from unsloth import FastVisionModel # FastLanguageModel for LLMs\nimport torch\n\nmodel_id = \"Qwen/Qwen2-VL-2B-Instruct\"\n\nmodel, tokenizer = FastVisionModel.from_pretrained(\n    model_id,\n    # load_in_4bit = True, # Use 4bit to reduce memory use. False for 16bit LoRA.\n    # use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for long context\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T02:00:37.310441Z","iopub.execute_input":"2025-09-13T02:00:37.310833Z","iopub.status.idle":"2025-09-13T02:01:51.223985Z","shell.execute_reply.started":"2025-09-13T02:00:37.310808Z","shell.execute_reply":"2025-09-13T02:01:51.223164Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = FastVisionModel.get_peft_model(\n    model,\n    finetune_vision_layers     = True, # False if not finetuning vision layers\n    finetune_language_layers   = True, # False if not finetuning language layers\n    finetune_attention_modules = True, # False if not finetuning attention layers\n    finetune_mlp_modules       = True, # False if not finetuning MLP layers\n\n    r = 16,           # The larger, the higher the accuracy, but might overfit\n    lora_alpha = 16,  # Recommended alpha == r at least\n    lora_dropout = 0,\n    bias = \"none\",\n    random_state = 3407,\n    use_rslora = False,  # We support rank stabilized LoRA\n    loftq_config = None, # And LoftQ\n    # target_modules = \"all-linear\", # Optional now! Can specify a list if needed\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T02:01:51.224830Z","iopub.execute_input":"2025-09-13T02:01:51.225020Z","iopub.status.idle":"2025-09-13T02:01:56.680068Z","shell.execute_reply.started":"2025-09-13T02:01:51.225005Z","shell.execute_reply":"2025-09-13T02:01:56.679361Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from datasets import load_dataset, Dataset\n\nsystem_message=\"You are a helpful assistant who can analyze the given images in detail and answer the question appropriately.\"\n\ndef convert_to_conversation(sample):\n    conversation = [\n        { \"role\": \"user\",\n          \"content\" : [\n            {\"type\" : \"text\",  \"text\"  : system_message},\n            {\"type\" : \"image\", \"image\" : sample[\"image\"]},\n              {\"type\" : \"text\",  \"text\"  : sample[\"query\"]}]\n        },\n        { \"role\" : \"assistant\",\n          \"content\" : [\n            {\"type\" : \"text\",  \"text\"  : sample[\"label\"]} ]\n        },\n    ]\n    return { \"messages\" : conversation }\n\ndataset = load_dataset(\"HuggingFaceM4/ChartQA\", split=\"train\", streaming=True) #.select(range(n_samples))\n# Take only first `n_samples`\ndataset = dataset.take(8000)\n\nconverted_dataset = [convert_to_conversation(sample) for sample in dataset]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T02:01:56.681387Z","iopub.execute_input":"2025-09-13T02:01:56.681700Z","iopub.status.idle":"2025-09-13T02:02:31.727066Z","shell.execute_reply.started":"2025-09-13T02:01:56.681671Z","shell.execute_reply":"2025-09-13T02:02:31.726198Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from unsloth import is_bf16_supported\nfrom unsloth.trainer import UnslothVisionDataCollator\nfrom trl import SFTTrainer, SFTConfig\n\nFastVisionModel.for_training(model) # Enable for training!\n\ntrainer = SFTTrainer(\n    model = model,\n    tokenizer = tokenizer,\n    data_collator = UnslothVisionDataCollator(model, tokenizer), # Must use!\n    train_dataset = converted_dataset,\n    args = SFTConfig(\n        per_device_train_batch_size = 2,\n        gradient_accumulation_steps = 10, #4\n        warmup_steps = 5,\n        max_steps = 100, #10\n        # num_train_epochs = 25, # Set this instead of max_steps for full training runs\n        learning_rate = 1e-4,#2e-4\n        fp16 = not is_bf16_supported(),\n        bf16 = is_bf16_supported(),\n        logging_steps = 1,\n        optim = \"adamw_8bit\",\n        weight_decay = 0.01,\n        lr_scheduler_type = \"linear\",\n        seed = 3407,\n        output_dir = \"outputs\",\n        report_to = \"none\",     # For Weights and Biases\n\n        # You MUST put the below items for vision finetuning:\n        remove_unused_columns = False,\n        dataset_text_field = \"\",\n        dataset_kwargs = {\"skip_prepare_dataset\": True},\n        dataset_num_proc = 10, #4\n        max_seq_length = 2048,\n    ),\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T02:21:23.142358Z","iopub.execute_input":"2025-09-13T02:21:23.143100Z","iopub.status.idle":"2025-09-13T02:21:23.254128Z","shell.execute_reply.started":"2025-09-13T02:21:23.143075Z","shell.execute_reply":"2025-09-13T02:21:23.253517Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#@title Show current memory stats\ngpu_stats = torch.cuda.get_device_properties(0)\nstart_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\nmax_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\nprint(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\nprint(f\"{start_gpu_memory} GB of memory reserved.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T02:21:26.507875Z","iopub.execute_input":"2025-09-13T02:21:26.508363Z","iopub.status.idle":"2025-09-13T02:21:26.513294Z","shell.execute_reply.started":"2025-09-13T02:21:26.508344Z","shell.execute_reply":"2025-09-13T02:21:26.512602Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer_stats = trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T02:21:29.021273Z","iopub.execute_input":"2025-09-13T02:21:29.022114Z","iopub.status.idle":"2025-09-13T02:26:58.541715Z","shell.execute_reply.started":"2025-09-13T02:21:29.022088Z","shell.execute_reply":"2025-09-13T02:26:58.540700Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#@title Show final memory and time stats\nused_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\nused_memory_for_lora = round(used_memory - start_gpu_memory, 3)\nused_percentage = round(used_memory         /max_memory*100, 3)\nlora_percentage = round(used_memory_for_lora/max_memory*100, 3)\nprint(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\nprint(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\nprint(f\"Peak reserved memory = {used_memory} GB.\")\nprint(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\nprint(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\nprint(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T02:20:37.242874Z","iopub.execute_input":"2025-09-13T02:20:37.243549Z","iopub.status.idle":"2025-09-13T02:20:37.249294Z","shell.execute_reply.started":"2025-09-13T02:20:37.243530Z","shell.execute_reply":"2025-09-13T02:20:37.248774Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.save_pretrained(\"lora_model_8k\") # Local saving\ntokenizer.save_pretrained(\"lora_model_8k\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T02:28:46.232236Z","iopub.execute_input":"2025-09-13T02:28:46.233147Z","iopub.status.idle":"2025-09-13T02:28:47.710005Z","shell.execute_reply.started":"2025-09-13T02:28:46.233117Z","shell.execute_reply":"2025-09-13T02:28:47.709318Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}